import streamlit as st
import os
import base64
from PIL import Image
from styles import aplicar_estilos

# Aplica estilos generales (si tienes algo definido en styles.py)
aplicar_estilos()

# üíú CSS personalizado: centrar tabs, colores suaves, efecto hover
st.markdown("""
<style>
/* Centrar las tabs horizontalmente */
[data-testid="stTabs"] > div {
    justify-content: center;
}

/* Estilo base de las tabs */
[data-testid="stTab"] {
    background-color: #eef0fc;
    border-radius: 10px;
    margin: 0 5px;
    padding: 8px 16px;
    transition: all 0.3s ease;
    color: #3b3b98;
    font-weight: 500;
    font-size: 0.95rem;
}

/* Hover con animaci√≥n */
[data-testid="stTab"]:hover {
    background-color: #dfe3fb;
    transform: scale(1.03);
}

/* Tab activa */
[data-testid="stTab"][aria-selected="true"] {
    background-color: #a29bfe;
    color: white;
    font-weight: 600;
}
</style>
""", unsafe_allow_html=True)

# T√≠tulo principal
st.markdown("""
<h1 style='text-align: center; color: #3b3b98; font-size: 3rem; margin-top: 20px;'>
    Arquitectura Utilizada
</h1>
""", unsafe_allow_html=True)
import base64

def image_to_base64(image_path):
    with open(image_path, "rb") as img_file:
        return base64.b64encode(img_file.read()).decode()


# Imagen
ruta_imagen = os.path.join("data", "arq.jpg")
if os.path.isfile(ruta_imagen):
    img_base64 = image_to_base64(ruta_imagen)
    st.markdown(
        f"""
        <div style="display: flex; justify-content: center; margin: 20px 0;">
            <img src="data:image/jpg;base64,{img_base64}" 
                 style="width: 1000px; height: 500px; object-fit: fill; border-radius: 12px;" 
                 alt="Arquitectura Instant Character">
        </div>
        """,
        unsafe_allow_html=True
    )
else:
    st.error("La imagen 'arq.jpg' no fue encontrada en la carpeta 'data'.")






# Subt√≠tulo
st.markdown("""
<h2 style='text-align: center; font-size: 2.2rem; color: #3b3b98;'>
    Explicaci√≥n de la Arquitectura
</h2>
""", unsafe_allow_html=True)


st.markdown("""
    <style>
    /* Centrar los tabs y ajustar margen izquierdo */
    div[data-baseweb="tab-list"] {
        justify-content: center;
        margin-left: 1%;
    }

    /* Cambiar tama√±o de la fuente en los tabs */
    button[data-baseweb="tab"] {
        font-size: 1.5rem !important;
        font-weight: 600 !important;
    }
    </style>
""", unsafe_allow_html=True)

# Tabs
tabs = st.tabs([
    " **1. Entrada de Datos**",
    " **2. Adaptador Visual**",
    " **3. Fusi√≥n Texto-Imagen**",
    " **Mecanismo de Atenci√≥n**"
])

#  Estilo uniforme del contenido
tab_style = """
<div style="text-align: center; font-size: 1.2rem; line-height: 1.7; max-width: 900px; margin: auto;">
"""

# Contenido de cada tab
tab_style = "font-size: 1.2rem; line-height: 1.7; max-width: 900px; margin: auto; text-align: center;"

def image_to_base64(image_path):
    with open(image_path, "rb") as img_file:
        encoded = base64.b64encode(img_file.read()).decode()
    return f"data:image/png;base64,{encoded}"

with tabs[0]:
    st.markdown(f"""
        <div style="{tab_style}">
            <b>Entrada de Datos</b>
        </div>
    """, unsafe_allow_html=True)

    st.markdown("<div style='margin-top: 30px;'></div>", unsafe_allow_html=True)

    col1, col2 = st.columns([1, 1])  # puedes ajustar las proporciones si quieres

    with col1:
        ruta_entrada = os.path.join("data", "random.jpg")
        if os.path.isfile(ruta_entrada):
            img_base64 = image_to_base64(ruta_entrada)
            st.markdown(f"""
                <div style="text-align: center;">
                    <img src="{img_base64}" width="400" alt="Entrada de Datos">
                </div>
            """, unsafe_allow_html=True)
        else:
            st.warning("La imagen 'Entrada.png' no fue encontrada.")

    with col2:
        st.markdown(f"""
        <div style="{tab_style} text-align: justify;">
            Se seleccionan aleatoriamente varias im√°genes del mismo personaje y se procesan para que el sistema pueda aprender su identidad visual.<br><br>
            <b>Pasos clave:</b><br>
            <b><i>1. Random Select:</i></b> selecciona al azar varias im√°genes del mismo personaje.<br>
            <b><i>2. Resize + Crop:</i></b> normaliza el tama√±o y encuadre para procesarlas mejor.<br><br>
             <b><i>Objetivo:</i></b> ‚Äúdame lo esencial de c√≥mo luce este personaje en distintas posturas/√°ngulos‚Äù.
        </div>
    """, unsafe_allow_html=True)

    st.markdown("<div style='margin-top: 10px;'></div>", unsafe_allow_html=True)
        
with tabs[1]:
    st.markdown(f"""
        <div style="{tab_style}">
            <b>Adaptador Visual (Visual Adapter)</b>
        </div>
    """, unsafe_allow_html=True)

    st.markdown("""
        <div style="text-align: justify; margin-top: 15px;">
            Este es el coraz√≥n del sistema. Aqu√≠ se extraen y refinan las caracter√≠sticas del personaje para proyectarlas al modelo base (DiT).
        </div>
    """, unsafe_allow_html=True)

    st.markdown("<div style='margin-top: 30px;'></div>", unsafe_allow_html=True)

    col1, col2 = st.columns([1, 1])

    with col1:
        ruta_adaptador = os.path.join("data", "adaptadorr.jpg")
        if os.path.isfile(ruta_adaptador):
            img_base64 = image_to_base64(ruta_adaptador)
            st.markdown(f"""
                <div style="text-align: center; margin-top: 20px;">
                    <img src="{img_base64}" width="600" alt="Adaptador Visual">
                </div>
            """, unsafe_allow_html=True)
        else:
            st.warning("La imagen 'adaptadorr.jpg' no fue encontrada en la carpeta 'data'.")

    with col2:
        st.markdown(f"""
    <div style="{tab_style}; font-size: 16px; line-height: 1.6;">
    
    <p style="margin-bottom: 20px; text-align: justify;"><b> Subcomponentes:</b></p>

    <p style="text-align: justify;"><b> a. SigLIP y DINOv2</b><br>
    &nbsp;&nbsp;&nbsp;‚Ä¢ Dos encoders preentrenados que extraen caracter√≠sticas del personaje.<br>
    &nbsp;&nbsp;&nbsp;‚Ä¢ <b>SigLIP:</b> entiende la relaci√≥n imagen-texto.<br>
    &nbsp;&nbsp;&nbsp;‚Ä¢ <b>DINOv2:</b> extrae informaci√≥n visual de bajo y alto nivel (textura, silueta, pose).<br>
    &nbsp;&nbsp;&nbsp;‚Ä¢ Ambos outputs se concatenan (<code>cat channel</code>) = representaci√≥n rica del personaje.</p>

    <p style="text-align: justify;"><b> b. MLP y Transformer (Intermedios)</b><br>
    &nbsp;&nbsp;&nbsp;‚Ä¢ Procesan jer√°rquicamente las caracter√≠sticas visuales.<br>
    &nbsp;&nbsp;&nbsp;‚Ä¢ Aplican un <i>Time Resampler</i>, que permite ubicar al personaje en el tiempo del proceso de difusi√≥n (como si fuera un paso dentro de la generaci√≥n de imagen).</p>


    </div>
    """, unsafe_allow_html=True)


with tabs[2]:
    st.markdown(f"""
        <div style="{tab_style}">
            <b>Fusi√≥n Texto-Imagen (Cross Attention)</b>
        </div>
    """, unsafe_allow_html=True)

    col1, col2 = st.columns([1, 1])

    with col1:
        ruta_fusion = os.path.join("data", "fusionn.jpg")
        if os.path.isfile(ruta_fusion):
            img_base64 = image_to_base64(ruta_fusion)
            st.markdown(f"""
                <div style="text-align: center; margin-top: 20px;">
                    <img src="{img_base64}" width="600" alt="Fusi√≥n Texto-Imagen">
                </div>
            """, unsafe_allow_html=True)
        else:
            st.warning("La imagen 'fusionn.jpg' no fue encontrada.")

    with col2:
        st.markdown(f"""
    <div style="{tab_style}; font-size: 16px; line-height: 1.6;">

    <p style="margin-bottom: 20px; text-align: justify;">
        <b>Este bloque representa al modelo generador principal (Diffusion Transformer).</b>
    </p>

    <p style="margin-bottom: 20px; text-align: justify;">
        <b>Cross Attention:</b><br>
        &nbsp;&nbsp;&nbsp;Le dice al modelo ‚Äúesto es c√≥mo se ve el personaje, y esto es lo que debe estar haciendo seg√∫n el texto.‚Äù
    </p>

    <p style="margin-bottom: 20px; text-align: justify;">
        &nbsp;&nbsp;&nbsp;‚óè Cada bloque azul es una capa Transformer.<br>
        &nbsp;&nbsp;&nbsp;‚óè El texto es embebido con una capa de Text Embedding.<br>
        &nbsp;&nbsp;&nbsp;‚óè El personaje (ya representado visualmente) y el texto interact√∫an mediante atenci√≥n cruzada para generar la imagen final.
    </p>

    <p style="margin-bottom: 5px; text-align: justify;">
        <b>Ejemplo textual:</b> ‚Äúa character is lying on beach‚Äù
    </p>
    <p style="text-align: justify;">
        ‚û° El modelo fusiona esa instrucci√≥n con la identidad visual para generar una imagen coherente y modificada.
    </p>

    </div>
    """, unsafe_allow_html=True)




with tabs[3]:
    st.markdown(f'<h3 style="text-align: center;">Atenci√≥n Cruzada</h3>', unsafe_allow_html=True)

    col1, col2, col3 = st.columns([1, 6, 1])
    with col2:
        img = Image.open("data/tensor.png")
        st.image(img, width=1200)

    col1, col2 = st.columns(2)

st.markdown("""
<style>
.guia {
    background-color: #f1f5f9;
    border-left: 6px solid #6366f1;
    padding: 1.2rem;
    border-radius: 12px;
    margin-top: 2rem;
    animation: fadeIn 1.2s ease-in-out;
}
.guia h3 {
    color: #4338ca;
    margin-bottom: 1rem;
}
.guia ul {
    list-style-type: none;
    padding-left: 0;
}
.guia li {
    margin-bottom: 0.8rem;
    line-height: 1.6;
}
.guia li span {
    font-weight: bold;
    color: #111827;
}
@keyframes fadeIn {
    from {opacity: 0;}
    to {opacity: 1;}
}
</style>
""", unsafe_allow_html=True)

with col1:
    st.markdown("""
    <div class="guia" style="font-size:16px; line-height:1.6; text-align: justify; padding-right:15px;">
        <h3>¬øQu√© hace?</h3>
        <p style="margin-bottom: 15px; text-align: justify;">
            Usa los vectores <b>Q (Query)</b>, <b>K (Key)</b> y <b>V (Value)</b> para combinar texto e imagen de manera inteligente.
        </p>
        <h3>Creaci√≥n de tensores Q, K y V:</h3>
        <p style="margin-bottom: 15px; text-align: justify;">
            Los tensores <b>Q (Query)</b>, <b>K (Key)</b> y <b>V (Value)</b> se generan a partir de las representaciones embebidas del texto y la imagen. 
            El texto se convierte en vectores a trav√©s de una capa de embedding que captura la sem√°ntica de la instrucci√≥n. 
            La imagen, por otro lado, se procesa mediante encoders visuales que extraen caracter√≠sticas espaciales y temporales del personaje o la escena.
        </p>
        <h3>Manejo de relaciones espaciales y temporales:</h3>
        <p style="margin-bottom: 15px; text-align: justify;">
            La arquitectura Scalable Diffusion Transformer, a trav√©s de su mecanismo de atenci√≥n, modela expl√≠citamente las relaciones espaciales y temporales dentro de la imagen. 
            Esto se logra utilizando las posiciones relativas de los p√≠xeles o tokens visuales y temporalizando la atenci√≥n para capturar c√≥mo el personaje evoluciona o se sit√∫a en el tiempo durante el proceso de difusi√≥n. 
            As√≠, el modelo entiende qu√© partes de la imagen deben modificarse o mantenerse coherentes a lo largo de la generaci√≥n o edici√≥n.
        </p>
    </div>
    """, unsafe_allow_html=True)

with col2:
    st.markdown("""
    <div class="guia" style="font-size:16px; line-height:1.6; text-align: justify; padding-left:15px;">
        <h3>¬øDe d√≥nde viene cada uno?</h3>
        <ul>
            <li><span>Q (Query):</span> Viene del texto, es la consulta que representa la instrucci√≥n o lo que quieres que pase en la imagen (ejemplo: ‚Äúel personaje est√° en la nieve‚Äù).</li>
            <li><span>K (Key):</span> Viene de la imagen, es la informaci√≥n visual que describe el personaje (pose, color, ropa, etc).</li>
            <li><span>V (Value):</span> Tambi√©n viene de la imagen, pero contiene la esencia visual a aplicar, es decir, lo que realmente se va a modificar o mantener.</li>
        </ul>
        <h3>¬øC√≥mo funciona?</h3>
        <p style="margin-bottom: 15px; text-align: justify;">
            El modelo ‚Äúpregunta‚Äù con <b>Q</b> al conjunto de claves <b>K</b> para identificar qu√© partes visuales son relevantes seg√∫n el texto, y luego usa <b>V</b> para generar o modificar la imagen respetando esa interacci√≥n.
        </p>
        <h3>¬øQu√© aprende?</h3>
        <p style="margin-bottom: 15px; text-align: justify;">
            Aprende a ‚Äúatender‚Äù solo a las partes del texto que deben cambiar la imagen y c√≥mo aplicar esos cambios de forma visual coherente, respetando la identidad previa del personaje.
        </p>
    </div>
    """, unsafe_allow_html=True)















